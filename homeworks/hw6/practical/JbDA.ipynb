{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgIHjec_9wuO"
      },
      "source": [
        "**SPML**\n",
        "\n",
        "**HW6**\n",
        "\n",
        "**Name: Javad Hezareh**\n",
        "\n",
        "**Student No.: 98101074**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2QKhc9H94VM"
      },
      "source": [
        "1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BJAHH85K90lQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLh3MCsi-LkW"
      },
      "source": [
        "2. Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rB5ycNUO-RQG"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(1,16,5), # 16*24*24\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16,32,5), # 32*20*20\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2), # 32*10*10\n",
        "            nn.Conv2d(32,64,5), # 64*6*6\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2) #64*3*3\n",
        "        )\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(64*3*3,100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,10)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer(x)\n",
        "        out = out.view(-1,64*3*3)\n",
        "        out = self.fc_layer(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlgMDm1R_bzk"
      },
      "source": [
        "3. Load original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "563DKviw_UYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c3f60a-3f26-4f98-f24a-23f30a3f570c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 216595439.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 39393721.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 67842098.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 26025312.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# todo: Define Batch size & Load MNIST dataset #\n",
        "device = torch.device(torch.cuda.current_device()) if torch.cuda.is_available() else torch.device('cpu')\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "mnist_train = datasets.MNIST('./data', train=True, download=True, transform=mnist_transform)\n",
        "mnist_test = datasets.MNIST('./data', train=False, download=True, transform=mnist_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5ElW2ZxYErl"
      },
      "source": [
        "## Training the substitute model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nX0w-T0waraC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469856ff-a29e-4da8-a8b8-1b38b337a334"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "oracle = CNN().to(device)\n",
        "\n",
        "# todo: load oracle's checkpoint\n",
        "oracle.load_state_dict(torch.load('./checkpoint.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcFGZQ1EYErl"
      },
      "source": [
        "Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "D0oRvs5wYErl"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ### TO DO ###\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1,16,5),          # B 16 24 24\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),         # B 16 12 12\n",
        "            nn.Conv2d(16, 32, 5),       # B 32 8 8\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32*8*8, 256),     # B 256\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)          # B 10\n",
        "        )\n",
        "        #############\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### TO DO ###\n",
        "        features = self.conv_layers(x)\n",
        "        out = self.fc(features)\n",
        "        #############\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ2urUdbYErl"
      },
      "source": [
        "Implement Jacobian-based Data Augmentation Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd.functional import jacobian"
      ],
      "metadata": {
        "id": "DE1U7vphyNkD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "lRNWEXhuYErl"
      },
      "outputs": [],
      "source": [
        "def train_JDA(net, X, oracle, epochs=45, lmbd=0.1, max_rho=6):\n",
        "    ### TO DO ###\n",
        "    ### Note that you can only use the prediction labels in the training\n",
        "    ### You can get the prediction labels using net(X).max(1).indices\n",
        "    def get_labeling(X, oracle):\n",
        "        print('\\t-labeling phase ...')\n",
        "        labels = []\n",
        "        loader = DataLoader(X, batch_size=batch_size, shuffle=False)\n",
        "        oracle.eval()\n",
        "        for x in loader:\n",
        "            x = x.to(device)\n",
        "            pred_labels = torch.argmax(oracle(x), dim=1)\n",
        "            labels.append(pred_labels)\n",
        "        print('\\t-labeling phase done!')\n",
        "        return torch.cat(labels, dim=0).squeeze()\n",
        "\n",
        "\n",
        "    def train_model(net, X, y, epochs):\n",
        "        print('\\t-training phase ...')\n",
        "        y = y.to(device)\n",
        "        X = X.to(device)\n",
        "        dataset = [(img, label) for img, label in zip(X, y)]\n",
        "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "        optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        net.train()\n",
        "        for epoch in range(epochs):\n",
        "            for imgs, labels in loader:\n",
        "                optimizer.zero_grad()\n",
        "                logits = net(imgs)\n",
        "                loss = criterion(logits, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        print('\\t-training phase done.')\n",
        "        return\n",
        "\n",
        "\n",
        "    def update_dataset(net, oracle, X, lmbd):\n",
        "        print('\\t-update phase ...')\n",
        "        loader = DataLoader(X, batch_size=batch_size, shuffle=False)\n",
        "        X = X.to(device)\n",
        "        oracle.eval()\n",
        "        net.eval()\n",
        "\n",
        "        new_X = []\n",
        "        for x in loader:\n",
        "            x = x.to(device)\n",
        "            oracle_label = torch.argmax(oracle(x), dim=1)\n",
        "            j_F = jacobian(net, x)\n",
        "            new_x = x + lmbd * j_F[range(len(x)), oracle_label, range(len(x))]\n",
        "            new_X.append(new_x)\n",
        "        print('\\t-update phase done.')\n",
        "        new_X = torch.cat(new_X, dim=0)\n",
        "        return torch.cat([X, new_X], dim=0)\n",
        "\n",
        "\n",
        "    for i in range(max_rho):\n",
        "        print(f'alg iteration {i} begins ...')\n",
        "        y = get_labeling(X, oracle)\n",
        "        train_model(net, X, y, epochs)\n",
        "        X = update_dataset(net, oracle, X, lmbd)\n",
        "    #############\n",
        "\n",
        "def compute_accuracy(net, X, y):\n",
        "    ### TO DO ###\n",
        "    predicted = torch.argmax(net(X), dim=1)\n",
        "    return (predicted == y).sum() / len(X)\n",
        "    #############"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "JfodgFU9YErm"
      },
      "outputs": [],
      "source": [
        "### TO DO ###\n",
        "### Select 100 images with their labels from the dataset, randomly\n",
        "indices = torch.randperm(len(mnist_train))[:100]\n",
        "JDA_train_X = (mnist_train.data[indices] / 255).unsqueeze(1)\n",
        "JDA_train_y = mnist_train.targets[indices]\n",
        "#############\n",
        "\n",
        "net = Net().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7HQNXfYJYErm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a1a686-f141-401b-e7cd-a1062da5959c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alg iteration 0 begins ...\n",
            "\t-labeling phase ...\n",
            "\t-labeling phase done!\n",
            "\t-training phase ...\n",
            "\t-training phase done.\n",
            "\t-update phase ...\n",
            "\t-update phase done.\n",
            "alg iteration 1 begins ...\n",
            "\t-labeling phase ...\n",
            "\t-labeling phase done!\n",
            "\t-training phase ...\n",
            "\t-training phase done.\n",
            "\t-update phase ...\n",
            "\t-update phase done.\n",
            "alg iteration 2 begins ...\n",
            "\t-labeling phase ...\n",
            "\t-labeling phase done!\n",
            "\t-training phase ...\n",
            "\t-training phase done.\n",
            "\t-update phase ...\n",
            "\t-update phase done.\n",
            "alg iteration 3 begins ...\n",
            "\t-labeling phase ...\n",
            "\t-labeling phase done!\n",
            "\t-training phase ...\n",
            "\t-training phase done.\n",
            "\t-update phase ...\n",
            "\t-update phase done.\n",
            "alg iteration 4 begins ...\n",
            "\t-labeling phase ...\n",
            "\t-labeling phase done!\n",
            "\t-training phase ...\n",
            "\t-training phase done.\n",
            "\t-update phase ...\n",
            "\t-update phase done.\n",
            "alg iteration 5 begins ...\n",
            "\t-labeling phase ...\n",
            "\t-labeling phase done!\n",
            "\t-training phase ...\n",
            "\t-training phase done.\n",
            "\t-update phase ...\n",
            "\t-update phase done.\n"
          ]
        }
      ],
      "source": [
        "train_JDA(net, JDA_train_X, oracle, epochs=100, lmbd=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "lQs24iepYErm"
      },
      "outputs": [],
      "source": [
        "### TO DO ###\n",
        "### load the whole test and train dataset in one full batch\n",
        "\n",
        "# _ = torch.utils.data.DataLoader(<?>, <?>, shuffle=True)\n",
        "train_X, train_y = mnist_train.data.unsqueeze(1) / 255, mnist_train.targets\n",
        "\n",
        "# _ = torch.utils.data.DataLoader(<?>, <?>, shuffle=True)\n",
        "test_X, test_y = mnist_test.data.unsqueeze(1) / 255, mnist_test.targets\n",
        "#############"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BgPy9iW2YErm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0065356e-b346-416a-cb9b-c9150f649844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train: 40.33 %\n",
            "accuracy on test: 41.27 %\n"
          ]
        }
      ],
      "source": [
        "### TO DO ###\n",
        "### compute accuracy of net on train and test\n",
        "train_X = train_X.to(device)\n",
        "test_X = test_X.to(device)\n",
        "train_y = train_y.to(device)\n",
        "test_y = test_y.to(device)\n",
        "\n",
        "print(f'accuracy on train: {compute_accuracy(net, train_X, train_y)*100:0.2f} %')\n",
        "print(f'accuracy on test: {compute_accuracy(net, test_X, test_y)*100:0.2f} %')\n",
        "#############"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}