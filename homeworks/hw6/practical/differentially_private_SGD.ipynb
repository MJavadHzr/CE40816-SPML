{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Name: Javad Hezareh**\n\n**Student Number: 98101074**","metadata":{"id":"Rcy4N9MDyYpC"}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.models import resnet18\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader","metadata":{"id":"LJ0Ovjt7uQKs","execution":{"iopub.status.busy":"2023-06-30T19:26:51.743748Z","iopub.execute_input":"2023-06-30T19:26:51.744184Z","iopub.status.idle":"2023-06-30T19:26:53.633111Z","shell.execute_reply.started":"2023-06-30T19:26:51.744149Z","shell.execute_reply":"2023-06-30T19:26:53.632122Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Initialization","metadata":{"id":"b_nPVxmi-17l"}},{"cell_type":"code","source":"cifar_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    transforms.CenterCrop(28)\n])\n\nmnist_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\nL = 32 # group size\n\ncifar_trainset = torchvision.datasets.CIFAR10(root='./cifar', train=True,\n                                              download=True, transform=cifar_transform)\ncifar_testset = torchvision.datasets.CIFAR10(root='./cifar', train=False,\n                                             download=True, transform=cifar_transform)\n\nmnist_trainset = torchvision.datasets.MNIST(root='./mnist', train=True,\n                                            download=True, transform=mnist_transform)\nmnist_testset = torchvision.datasets.MNIST(root='./mnist', train=False,\n                                           download=True, transform=mnist_transform)\n\n#################################### To Do (2 pts) #############################\n# Define trainloader and testloader with given batch size.\n# Set shuffle parameter to True for trainloader and False for testloader.\n################################################################################\ncifar_train_loader = DataLoader(cifar_trainset, batch_size=L, shuffle=True)\ncifar_test_loader = DataLoader(cifar_testset, batch_size=L, shuffle=False)\n\nmnist_train_loader = DataLoader(mnist_trainset, batch_size=L, shuffle=True)\nmnist_test_loader = DataLoader(mnist_testset, batch_size=L, shuffle=False)\n##################################### End ######################################\n\ndevice = torch.device(torch.cuda.current_device()) if torch.cuda.is_available() else torch.device('cpu')\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G6aIilOlwHKs","outputId":"9cb30661-96b5-46e8-f0e1-bf26d9fa2792","execution":{"iopub.status.busy":"2023-06-30T19:26:53.636936Z","iopub.execute_input":"2023-06-30T19:26:53.637408Z","iopub.status.idle":"2023-06-30T19:27:02.175381Z","shell.execute_reply.started":"2023-06-30T19:26:53.637383Z","shell.execute_reply":"2023-06-30T19:27:02.174362Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:03<00:00, 49190593.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./cifar/cifar-10-python.tar.gz to ./cifar\nFiles already downloaded and verified\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 139143670.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 95008387.31it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ./mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 1648877/1648877 [00:00<00:00, 48428238.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 11441759.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST/raw\n\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, in_channel):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(in_channel, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.fc1 = nn.Linear(9216, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        output = torch.softmax(x, dim=1)\n        return output","metadata":{"id":"L29X5NbvwTNZ","execution":{"iopub.status.busy":"2023-06-30T19:27:02.177233Z","iopub.execute_input":"2023-06-30T19:27:02.178154Z","iopub.status.idle":"2023-06-30T19:27:02.186641Z","shell.execute_reply.started":"2023-06-30T19:27:02.178118Z","shell.execute_reply":"2023-06-30T19:27:02.185600Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## differentially private SGD","metadata":{"id":"QN8bFXTe-9IJ"}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nlr=0.001","metadata":{"id":"RyXDAyypx5JP","execution":{"iopub.status.busy":"2023-06-30T19:27:02.189068Z","iopub.execute_input":"2023-06-30T19:27:02.189530Z","iopub.status.idle":"2023-06-30T19:27:02.204058Z","shell.execute_reply.started":"2023-06-30T19:27:02.189507Z","shell.execute_reply":"2023-06-30T19:27:02.203055Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def DP_SGD(model, trainloader, criterion, optimizer, sigma, C):\n    \"\"\"\n    sigma: noise scale\n    C: gradient norm bound\n    \"\"\"\n    #################################### To Do (16 pts) ##########################\n    model.train()\n    for batch in trainloader:\n        for param in model.parameters():\n            param.accumulated_grads = []\n\n        imgs, labels = batch\n        imgs = imgs.to(device)\n        labels = labels.to(device)\n\n        # 1. For each sample, compute gradients of loss w.r.t. parameters (5 pts)\n        for i in range(len(imgs)):\n            img = imgs[i].unsqueeze(0)\n            label = labels[i].unsqueeze(0)\n\n            prob = model(img)\n            loss = criterion(prob, label)\n            loss.backward()\n\n        # 2. Clip each parameter's per-sample gradient (4 pts)\n            for param in model.parameters():\n                grad = param.grad.detach().clone()\n                clip_grad_norm_(grad, max_norm=C)\n                param.accumulated_grads.append(grad)\n                param.grad = None\n\n        # 3. Add noise and aggregate back accumulated grads with torch.stack (4 pts)\n        for param in model.parameters():\n            accumulated_grad = torch.stack(param.accumulated_grads, dim=0)\n            accumulated_grad += torch.randn_like(accumulated_grad) * sigma * C\n            param.grad = accumulated_grad.sum(dim=0) / L\n#             param.grad += torch.randn_like(param.grad) * sigma * C\n\n        # 4. Update model's weights and reset grad for the next iteration (3 pts)\n        for param in model.parameters():\n            optimizer.step()\n#             new_param = param - lr * param.grad\n#             param = param.detach()\n#             param.copy_(new_param)\n            optimizer.zero_grad()\n#             param.grad = None\n    ##################################### End ####################################","metadata":{"id":"TLBMCrp22G5c","execution":{"iopub.status.busy":"2023-06-30T19:27:02.206515Z","iopub.execute_input":"2023-06-30T19:27:02.207238Z","iopub.status.idle":"2023-06-30T19:27:02.218316Z","shell.execute_reply.started":"2023-06-30T19:27:02.207205Z","shell.execute_reply":"2023-06-30T19:27:02.217322Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation\nNow, we want to test this algorithm on CIFAR10 and MNIST datasets.","metadata":{"id":"CXxbIypB7uSq"}},{"cell_type":"markdown","source":"### Effect of $\\sigma$ (and $\\epsilon$) (6 pts)\nPlot accuracy vs. epoch for various noise scale $\\sigma = 2, 4, 8$ for both datasets. Plot both training and testing accuracy.\n\nChange the code above if needed.","metadata":{"id":"GOBIxeUJ_OvB"}},{"cell_type":"code","source":"def cal_accuracy(model, dataloader):\n    model.eval()\n    with torch.no_grad():\n        acc = 0\n        N = 0\n        for (imgs, labels) in dataloader:\n            imgs = imgs.to(device)\n            labels = labels.to(device)\n\n            probs = model(imgs)\n            preds = torch.argmax(probs, dim=1)\n            acc += (preds == labels).sum().item()\n            N += len(imgs)\n\n    return acc / N","metadata":{"id":"xym63xkeyL6x","execution":{"iopub.status.busy":"2023-06-30T19:27:04.399034Z","iopub.execute_input":"2023-06-30T19:27:04.399410Z","iopub.status.idle":"2023-06-30T19:27:04.406250Z","shell.execute_reply.started":"2023-06-30T19:27:04.399370Z","shell.execute_reply":"2023-06-30T19:27:04.405281Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def train_DP(model, loader, epoch_n, sigma, C):\n    train_loader = loader[0]\n    test_loader = loader[1]\n    \n    train_accs = []\n    test_accs = []\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n    for epoch in range(epoch_n):\n        DP_SGD(model, train_loader, criterion, optimizer, sigma, C)\n        \n        train_acc = cal_accuracy(model, train_loader)\n        test_acc = cal_accuracy(model, test_loader)\n        train_accs.append(train_acc)\n        test_accs.append(test_acc)\n        \n        print(f'Epoch: {epoch}\\ttrain acc: {train_acc:.3f}\\ttest acc: {test_acc:.3f}')\n        print('-'*50)\n    \n    return train_accs, test_accs","metadata":{"execution":{"iopub.status.busy":"2023-06-30T19:27:27.935728Z","iopub.execute_input":"2023-06-30T19:27:27.936094Z","iopub.status.idle":"2023-06-30T19:27:27.944032Z","shell.execute_reply.started":"2023-06-30T19:27:27.936049Z","shell.execute_reply":"2023-06-30T19:27:27.942941Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"sigmas = [2, 4, 8]\nepochs = [6, 6, 6]\nC = 4\n\nresults = dict()\ndatasets = [(mnist_train_loader, mnist_test_loader), (cifar_train_loader, cifar_test_loader)]\n\nfor i, loader in enumerate(datasets):\n    dataset_name = 'MNIST' if i==0 else 'CIFAR10'\n    in_channel = 1 if i==0 else 3\n    results[dataset_name] = {'train': dict(), 'test': dict()}\n\n    for epoch_n, sigma in zip(epochs, sigmas):\n        print(f\"Dataset: {dataset_name}\\tC: {C}\\tSigma: {sigma}\")\n        print('-'*50)\n        \n        model = Net(in_channel).to(device)\n        train_accs, test_accs = train_DP(model, loader, epoch_n, sigma, C)\n        \n        results[dataset_name]['train'][sigma] = train_accs\n        results[dataset_name]['test'][sigma] = test_accs","metadata":{"id":"JSAkQSvJlS4c","execution":{"iopub.status.busy":"2023-06-30T17:15:44.174673Z","iopub.execute_input":"2023-06-30T17:15:44.175111Z","iopub.status.idle":"2023-06-30T18:35:33.819787Z","shell.execute_reply.started":"2023-06-30T17:15:44.175079Z","shell.execute_reply":"2023-06-30T18:35:33.818520Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Dataset: MNIST\tC: 4\tSigma: 2\n--------------------------------------------------\nEpoch: 0\ttrain acc: 0.458\ttest acc: 0.466\n--------------------------------------------------\nEpoch: 1\ttrain acc: 0.527\ttest acc: 0.532\n--------------------------------------------------\nEpoch: 2\ttrain acc: 0.530\ttest acc: 0.533\n--------------------------------------------------\nEpoch: 3\ttrain acc: 0.550\ttest acc: 0.551\n--------------------------------------------------\nEpoch: 4\ttrain acc: 0.586\ttest acc: 0.589\n--------------------------------------------------\nEpoch: 5\ttrain acc: 0.572\ttest acc: 0.577\n--------------------------------------------------\nDataset: MNIST\tC: 4\tSigma: 4\n--------------------------------------------------\nEpoch: 0\ttrain acc: 0.311\ttest acc: 0.314\n--------------------------------------------------\nEpoch: 1\ttrain acc: 0.308\ttest acc: 0.312\n--------------------------------------------------\nEpoch: 2\ttrain acc: 0.282\ttest acc: 0.289\n--------------------------------------------------\nEpoch: 3\ttrain acc: 0.346\ttest acc: 0.345\n--------------------------------------------------\nEpoch: 4\ttrain acc: 0.361\ttest acc: 0.361\n--------------------------------------------------\nEpoch: 5\ttrain acc: 0.389\ttest acc: 0.392\n--------------------------------------------------\nDataset: MNIST\tC: 4\tSigma: 8\n--------------------------------------------------\nEpoch: 0\ttrain acc: 0.213\ttest acc: 0.215\n--------------------------------------------------\nEpoch: 1\ttrain acc: 0.193\ttest acc: 0.191\n--------------------------------------------------\nEpoch: 2\ttrain acc: 0.173\ttest acc: 0.175\n--------------------------------------------------\nEpoch: 3\ttrain acc: 0.199\ttest acc: 0.199\n--------------------------------------------------\nEpoch: 4\ttrain acc: 0.181\ttest acc: 0.184\n--------------------------------------------------\nEpoch: 5\ttrain acc: 0.123\ttest acc: 0.122\n--------------------------------------------------\nDataset: CIFAR10\tC: 4\tSigma: 2\n--------------------------------------------------\nEpoch: 0\ttrain acc: 0.128\ttest acc: 0.127\n--------------------------------------------------\nEpoch: 2\ttrain acc: 0.188\ttest acc: 0.185\n--------------------------------------------------\nEpoch: 3\ttrain acc: 0.216\ttest acc: 0.218\n--------------------------------------------------\nEpoch: 4\ttrain acc: 0.229\ttest acc: 0.223\n--------------------------------------------------\nEpoch: 5\ttrain acc: 0.237\ttest acc: 0.237\n--------------------------------------------------\nDataset: CIFAR10\tC: 4\tSigma: 4\n--------------------------------------------------\nEpoch: 0\ttrain acc: 0.136\ttest acc: 0.134\n--------------------------------------------------\nEpoch: 1\ttrain acc: 0.141\ttest acc: 0.140\n--------------------------------------------------\nEpoch: 2\ttrain acc: 0.127\ttest acc: 0.127\n--------------------------------------------------\nEpoch: 3\ttrain acc: 0.147\ttest acc: 0.145\n--------------------------------------------------\nEpoch: 4\ttrain acc: 0.148\ttest acc: 0.147\n--------------------------------------------------\nEpoch: 5\ttrain acc: 0.137\ttest acc: 0.138\n--------------------------------------------------\nDataset: CIFAR10\tC: 4\tSigma: 8\n--------------------------------------------------\nEpoch: 0\ttrain acc: 0.102\ttest acc: 0.104\n--------------------------------------------------\nEpoch: 1\ttrain acc: 0.112\ttest acc: 0.117\n--------------------------------------------------\nEpoch: 3\ttrain acc: 0.117\ttest acc: 0.121\n--------------------------------------------------\nEpoch: 4\ttrain acc: 0.115\ttest acc: 0.120\n--------------------------------------------------\nEpoch: 5\ttrain acc: 0.130\ttest acc: 0.133\n--------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"for d_name in ['MNIST', 'CIFAR10']:\n    for sigma in sigmas:\n        plt.plot(results[d_name]['train'][sigma], label=f'{d_name};train;{sigma}')\n        plt.plot(results[d_name]['test'][sigma], label=f'{d_name};test;{sigma}')\nplt.legend();","metadata":{"id":"X-E1hBauoeYV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Effect of $\\epsilon, \\delta$ (6 pts)\nPlot accuracy vs. $\\epsilon$ (according to formulas in the lectures) in range $(10^{-1}, 10)$ for $\\delta=10^{-i}, i\\in\\{2, 3, 4, 5\\}$ for both datasets.","metadata":{"id":"UFcZvui8_tql"}},{"cell_type":"code","source":"deltas = [10**(-i) for i in range(2, 6)]\nepsilons = np.linspace(0.1, 10, num=5)\nC_values = 4\nepoch_n = 8\n\nresults = dict()\ndatasets = [(mnist_train_loader, mnist_test_loader), (cifar_train_loader, cifar_test_loader)]\n\nfor i, loader in enumerate(datasets):\n    dataset_name = 'MNIST' if i==0 else 'CIFAR10'\n    in_channel = 1 if i==0 else 3\n    results[dataset_name] = {'train': dict(), 'test': dict()}\n\n    for epsilon in epsilons:\n        results[dataset_name]['train'][epsilon] = []\n        results[dataset_name]['test'][epsilon] = []\n        for delta in deltas:\n            sigma = np.sqrt(2*np.log(1.25/delta))/epsilon\n            print(f\"Dataset: {dataset_name}\\tC: {C}\\tSigma: {sigma}\")\n            print('-'*50)\n            \n            model = Net(in_channel).to(device)\n            train_accs, test_accs = train_DP(model, loader, epoch_n, sigma, C)\n            \n            results[dataset_name]['train'][epsilon].append(np.max(train_accs))\n            results[dataset_name]['test'][epsilon].append(np.max(test_accs))","metadata":{"id":"zLcxWmk5ATqy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Effect of clipping bound (3 pts)\nPlot train and test accuracy vs. $C=1, 2, ..., 10$ for both datasets.","metadata":{"id":"4pVu6HhXBsoT"}},{"cell_type":"code","source":"sigma = 4\nC_values = range(1, 11)\nepoch_n = 10\n\nresults = dict()\ndatasets = [(mnist_train_loader, mnist_test_loader), (cifar_train_loader, cifar_test_loader)]\n\nfor i, loader in enumerate(datasets):\n    dataset_name = 'MNIST' if i==0 else 'CIFAR10'\n    in_channel = 1 if i==0 else 3\n    results[dataset_name] = {'train': [], 'test': []}\n\n    for C in C_values:\n        print(f\"Dataset: {dataset_name}\\tC: {C}\\tSigma: {sigma}\")\n        print('-'*50)\n        \n        model = Net(in_channel).to(device)\n        train_accs, test_accs = train_DP(model, loader, epoch_n, sigma, C)\n        \n        results[dataset_name]['train'].append(np.max(train_accs))\n        results[dataset_name]['test'].append(np.max(test_accs))","metadata":{"id":"l00Tl-CkB5D6","execution":{"iopub.status.busy":"2023-06-30T19:29:04.915164Z","iopub.execute_input":"2023-06-30T19:29:04.915534Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Dataset: MNIST\tC: 1\tSigma: 4\n--------------------------------------------------\nEpoch: 0\ttrain acc: 0.350\ttest acc: 0.358\n--------------------------------------------------\nEpoch: 1\ttrain acc: 0.711\ttest acc: 0.718\n--------------------------------------------------\nEpoch: 2\ttrain acc: 0.779\ttest acc: 0.785\n--------------------------------------------------\nEpoch: 3\ttrain acc: 0.793\ttest acc: 0.803\n--------------------------------------------------\nEpoch: 4\ttrain acc: 0.801\ttest acc: 0.809\n--------------------------------------------------\nEpoch: 5\ttrain acc: 0.801\ttest acc: 0.807\n--------------------------------------------------\nEpoch: 6\ttrain acc: 0.797\ttest acc: 0.801\n--------------------------------------------------\nEpoch: 8\ttrain acc: 0.806\ttest acc: 0.813\n--------------------------------------------------\nEpoch: 9\ttrain acc: 0.811\ttest acc: 0.823\n--------------------------------------------------\nDataset: MNIST\tC: 2\tSigma: 4\n--------------------------------------------------\nEpoch: 0\ttrain acc: 0.520\ttest acc: 0.545\n--------------------------------------------------\nEpoch: 1\ttrain acc: 0.652\ttest acc: 0.661\n--------------------------------------------------\nEpoch: 3\ttrain acc: 0.676\ttest acc: 0.684\n--------------------------------------------------\nEpoch: 4\ttrain acc: 0.697\ttest acc: 0.711\n--------------------------------------------------\nEpoch: 5\ttrain acc: 0.675\ttest acc: 0.689\n--------------------------------------------------\nEpoch: 6\ttrain acc: 0.753\ttest acc: 0.758\n--------------------------------------------------\nEpoch: 7\ttrain acc: 0.762\ttest acc: 0.763\n--------------------------------------------------\nEpoch: 8\ttrain acc: 0.770\ttest acc: 0.776\n--------------------------------------------------\nEpoch: 9\ttrain acc: 0.777\ttest acc: 0.783\n--------------------------------------------------\nDataset: MNIST\tC: 3\tSigma: 4\n--------------------------------------------------\nEpoch: 1\ttrain acc: 0.542\ttest acc: 0.544\n--------------------------------------------------\nEpoch: 2\ttrain acc: 0.598\ttest acc: 0.594\n--------------------------------------------------\nEpoch: 3\ttrain acc: 0.599\ttest acc: 0.610\n--------------------------------------------------\nEpoch: 4\ttrain acc: 0.614\ttest acc: 0.626\n--------------------------------------------------\nEpoch: 5\ttrain acc: 0.641\ttest acc: 0.642\n--------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}